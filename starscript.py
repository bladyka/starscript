import streamlit as st
from sentence_transformers import SentenceTransformer, util
import json
import os
import hashlib

# Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»Ð¸ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
model = SentenceTransformer('all-MiniLM-L6-v2')

# Ð‘Ð°Ð·Ð¾Ð²Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ‚Ð¾Ð² Ð—Ð²Ñ‘Ð·Ð´Ð½Ð¾Ð³Ð¾ Ð¡ÐºÑ€Ð¸Ð¿Ñ‚Ð°
BASE_CONCEPTS = {
    "water": "sel",
    "fire": "ver",
    "earth": "tur",
    "wind": "kai",
    "movement": "nol",
    "light": "phi",
    "darkness": "zor",
    "object": "kal",
    "life": "hal",
    "death": "mir",
    "tree": "lor",
    "metal": "zek",
    "sky": "tha",
    "sound": "rak",
    "energy": "ven",
    "emotion": "lii",
    "structure": "bal",
    "technology": "syn",
    "knowledge": "mek",
    "heat": "zor",
    "space": "qel",
    "body": "kor",
    "limb": "dra",
    "mother": "hala",
    "sun": "suur",
    "engine": "syn-nol-ven",
    "leg": "kor-dra",
    "human": "haleya",
    "love": "lii-hal",
    "boat": "kal-nol-sel-lor",
    "star": "suur"
}

# ÐŸÑƒÑ‚ÑŒ Ð´Ð»Ñ Ñ…Ñ€Ð°Ð½ÐµÐ½Ð¸Ñ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ ÑÐ»Ð¾Ð²Ð°Ñ€Ñ
DYNAMIC_DICT_PATH = "dynamic_dict.json"

def load_dynamic_dict():
    if os.path.exists(DYNAMIC_DICT_PATH):
        with open(DYNAMIC_DICT_PATH, "r", encoding="utf-8") as f:
            return json.load(f)
    else:
        return {}

def save_dynamic_dict(d):
    with open(DYNAMIC_DICT_PATH, "w", encoding="utf-8") as f:
        json.dump(d, f, ensure_ascii=False, indent=2)

dynamic_dict = load_dynamic_dict()

# ÐŸÐ¾Ð´Ð³Ð¾Ñ‚Ð¾Ð²ÐºÐ° Ð±Ð°Ð·Ñ‹ Ð´Ð»Ñ ÑÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¾Ð³Ð¾ Ð¿Ð¾Ð¸ÑÐºÐ°
base_phrases = list(BASE_CONCEPTS.keys())
base_embeddings = model.encode(base_phrases, convert_to_tensor=True)

def semantic_translate(word):
    word_lower = word.lower()
    if word_lower in dynamic_dict:
        return dynamic_dict[word_lower], "Cached translation"

    # ÐŸÑ€ÑÐ¼Ð¾Ðµ ÑÐ¾Ð²Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ Ð² Ð±Ð°Ð·Ð¾Ð²Ð¾Ð¼ ÑÐ»Ð¾Ð²Ð°Ñ€Ðµ
    if word_lower in BASE_CONCEPTS:
        return BASE_CONCEPTS[word_lower], "Direct base concept match"

    # Ð¡ÐµÐ¼Ð°Ð½Ñ‚Ð¸Ñ‡ÐµÑÐºÐ¸Ð¹ Ð¿Ð¾Ð¸ÑÐº Ð¿Ð¾ Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¼ ÐºÐ¾Ð½Ñ†ÐµÐ¿Ñ‚Ð°Ð¼
    query_emb = model.encode(word_lower, convert_to_tensor=True)
    hits = util.semantic_search(query_emb, base_embeddings, top_k=3)[0]

    threshold = 0.5
    parts = []
    explanation = []
    for hit in hits:
        if hit['score'] >= threshold:
            concept = base_phrases[hit['corpus_id']]
            parts.append(BASE_CONCEPTS[concept])
            explanation.append(f"{concept} ({hit['score']:.2f})")

    if not parts:
        hash_key = hashlib.md5(word_lower.encode()).hexdigest()[:4]
        alien_word = f"???-{hash_key}"
        dynamic_dict[word_lower] = alien_word
        save_dynamic_dict(dynamic_dict)
        return alien_word, "No similar concepts found"

    alien_word = "-".join(sorted(set(parts)))
    dynamic_dict[word_lower] = alien_word
    save_dynamic_dict(dynamic_dict)
    return alien_word, " + ".join(explanation)

# Streamlit UI
st.title("ðŸŒŒ Zvezdniy Skript Ultimate Translator")
input_text = st.text_input("Enter any English word or phrase:")

if input_text:
    words = input_text.strip().split()
    translations = []
    explanations = []
    for w in words:
        tr, expl = semantic_translate(w)
        translations.append(tr)
        explanations.append(f"**{w}** â†’ {tr} ({expl})")

    st.subheader("Translation:")
    st.write(" ".join(translations))

    st.subheader("Explanation:")
    st.markdown("\n\n".join(explanations))
